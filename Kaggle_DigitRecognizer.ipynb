{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(os.path.join('DigitRecognizer','train.csv'))\n",
    "test = pd.read_csv(os.path.join('DigitRecognizer','test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"label\"]\n",
    "x_train = train.drop(labels = [\"label\"],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing data in train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "x_train = x_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image into 3D arrays\n",
    "x_train = x_train.values.reshape(-1,28,28,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train val split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I learnt the coding techniques for building a CNN from Hands-On Machine Learning (by Aurelien Geron) as well as Yassine Ghouzam's Kaggle notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "    # Layer 1\n",
    "    keras.layers.Conv2D(filters = 32, kernel_size = 5, padding = \"same\", activation = \"relu\", input_shape = [28,28,1]),\n",
    "    keras.layers.MaxPooling2D (pool_size = 2, strides = 2),\n",
    " \n",
    "    # Layer 2\n",
    "    keras.layers.Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = \"relu\"),\n",
    "    keras.layers.Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = \"relu\"),\n",
    "    keras.layers.MaxPooling2D (pool_size = 2, strides = 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    # Layer 3\n",
    "    keras.layers.Dense(256, activation = \"relu\"), \n",
    "    keras.layers.Dropout(0.5),\n",
    "     \n",
    "    #Layer 4\n",
    "    keras.layers.Dense(10, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# opt = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = opt, \n",
    "              loss = \"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,  # horizontal shift (relative to total width)\n",
    "        height_shift_range=0.1,  # vertical shift (relative to total height)\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\"mnist.h5\",                                                 \n",
    "                                monitor = 'val_accuracy',                                                \n",
    "                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce learning by lr*0.5 when val_accuracy value plateaus for 3 epochs\n",
    "lr_cb = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                          patience=2, \n",
    "                          verbose=1,                                             \n",
    "                          factor=0.5,                                             \n",
    "                          min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_cb = EarlyStopping(patience=3,                                                  \n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "590/590 - 145s - loss: 0.3595 - accuracy: 0.8853 - val_loss: 0.0710 - val_accuracy: 0.9793\n",
      "Epoch 2/15\n",
      "590/590 - 145s - loss: 0.1218 - accuracy: 0.9643 - val_loss: 0.0526 - val_accuracy: 0.9848\n",
      "Epoch 3/15\n",
      "590/590 - 149s - loss: 0.0955 - accuracy: 0.9719 - val_loss: 0.0420 - val_accuracy: 0.9888\n",
      "Epoch 4/15\n",
      "590/590 - 152s - loss: 0.0763 - accuracy: 0.9769 - val_loss: 0.0357 - val_accuracy: 0.9895\n",
      "Epoch 5/15\n",
      "590/590 - 153s - loss: 0.0655 - accuracy: 0.9809 - val_loss: 0.0287 - val_accuracy: 0.9917\n",
      "Epoch 6/15\n",
      "590/590 - 156s - loss: 0.0599 - accuracy: 0.9814 - val_loss: 0.0288 - val_accuracy: 0.9910\n",
      "Epoch 7/15\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "590/590 - 169s - loss: 0.0546 - accuracy: 0.9840 - val_loss: 0.0257 - val_accuracy: 0.9917\n",
      "Epoch 8/15\n",
      "590/590 - 142s - loss: 0.0397 - accuracy: 0.9880 - val_loss: 0.0236 - val_accuracy: 0.9931\n",
      "Epoch 9/15\n",
      "590/590 - 145s - loss: 0.0352 - accuracy: 0.9896 - val_loss: 0.0198 - val_accuracy: 0.9940\n",
      "Epoch 10/15\n",
      "590/590 - 141s - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.0245 - val_accuracy: 0.9931\n",
      "Epoch 11/15\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "590/590 - 142s - loss: 0.0330 - accuracy: 0.9904 - val_loss: 0.0181 - val_accuracy: 0.9938\n",
      "Epoch 12/15\n",
      "590/590 - 146s - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.0189 - val_accuracy: 0.9952\n",
      "Epoch 13/15\n",
      "590/590 - 143s - loss: 0.0263 - accuracy: 0.9922 - val_loss: 0.0160 - val_accuracy: 0.9952\n",
      "Epoch 14/15\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "590/590 - 142s - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0171 - val_accuracy: 0.9948\n",
      "Epoch 15/15\n",
      "590/590 - 149s - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.0165 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size= batch_size),\n",
    "                              epochs = epoch, \n",
    "                              validation_data = (x_val,y_val),\n",
    "                              verbose = 2, \n",
    "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                              callbacks=[checkpoint_cb, lr_cb, early_stop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix of validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict (x_val) # class probabilities\n",
    "y_pred_class = np.argmax (y_pred,axis = 1)  # class with highest prob (i.e. predicted class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax (y_val,axis = 1) # class with prob of 1 (i.e. true class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[411,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 484,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,   0, 401,   0,   0,   0,   0,   0,   2,   0],\n",
       "       [  0,   0,   0, 416,   0,   0,   0,   0,   2,   0],\n",
       "       [  0,   0,   0,   0, 455,   0,   1,   0,   0,   5],\n",
       "       [  0,   0,   0,   0,   0, 369,   1,   0,   2,   0],\n",
       "       [  0,   0,   0,   0,   1,   0, 411,   0,   1,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0, 445,   0,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,   0, 380,   1],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,   0,   0, 408]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix (y_true, y_pred_class) \n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Predicted class')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mat, cmap = plt.cm.gray)\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sum = conf_mat.sum(axis=1, keepdims=True)\n",
    "norm_conf_mat = conf_mat / row_sum\n",
    "np.fill_diagonal(norm_conf_mat, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14991d2d4c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAJ0UlEQVR4nO3dz4tdhR2G8fdtRtEkFYV2YyKNQrEVoUYvJRpxYQy0VXTThYJC3WTTahRBtAv9B0R0UYQh1o1BFzGLIsVaUBdZGJwkAxrHFlGbRCOmi2pwkwTfLu4tJJmYe6Zzzpx7830+IGTGm+PLOA/n/pozTiIAF7Yf9D0AQPcIHSiA0IECCB0ogNCBAggdKKC30G3/yvY/bH9s+4m+djRl+yrbb9tesH3Q9va+NzVhe5XtA7Zf73tLE7Yvt73L9kejr/XNfW8ax/ajo++JD2y/YvuSvjedrZfQba+S9CdJv5Z0naT7bF/Xx5YlOCXpsSQ/l7RJ0u+nYLMkbZe00PeIJXhe0htJfibpF5rw7bbXSXpY0iDJ9ZJWSbq331WL9XVG/6Wkj5N8kuSEpFcl3dPTlkaSHE2yf/Tn4xp+A67rd9X52V4v6U5JO/re0oTtyyTdJulFSUpyIsl/+l3VyIykS23PSFot6Yue9yzSV+jrJB0+7eMjmvBoTmd7g6SNkvb2u2Ss5yQ9Lum7voc0dI2kY5JeGj3c2GF7Td+jzifJ55KekXRI0lFJXyd5s99Vi/UVus/xual4L67ttZJek/RIkm/63vN9bN8l6ask+/resgQzkm6U9EKSjZK+lTTRz9/YvkLDe6NXS7pS0hrb9/e7arG+Qj8i6arTPl6vCby7czbbF2kY+c4ku/veM8ZmSXfb/kzDh0a3236530ljHZF0JMn/7int0jD8SXaHpE+THEtyUtJuSbf0vGmRvkJ/T9JPbV9t+2INn7z4S09bGrFtDR87LiR5tu894yR5Msn6JBs0/Pq+lWTizjSnS/KlpMO2rx19aoukD3uc1MQhSZtsrx59j2zRBD6BONPHfzTJKdt/kPQ3DZ+l/HOSg31sWYLNkh6Q9L7t+dHn/pjkrz1uuhA9JGnn6ATwiaQHe95zXkn22t4lab+Gr8wckDTb76rFzI+pAhc+3hkHFEDoQAGEDhRA6EABhA4U0Hvotrf1vWEppm2vxOaVMOl7ew9d0kR/gc5h2vZKbF4JE713EkIH0LFO3jBjm3fhAD1JsuiHxjijAwUQOlAAoQMFEDpQAKEDBRA6UECj0KftGuwAzjT2dfTRNdj/KWmrhtf0ek/SfUm+9xI/vI4O9Of/fR196q7BDuBMTUKf6muwA2h2cchG12Af/fTORL+xH6iqSeiNrsGeZFajq1/yGB2YLE3uuk/dNdgBnGnsGX1Kr8EO4DT8mCpwgeHHVIGiCB0ogNCBAggdKIDQgQJ6+bXJwLS44YYbOjv2/Pz8+Bu1hDM6UAChAwUQOlAAoQMFEDpQAKEDBRA6UAChAwUQOlAAoQMFEDpQAKEDBRA6UAChAwUQOlAAoQMFEDpQAKEDBRA6UAChAwUQOlAAoQMFcLln4Dy2bt3a2bG53DOAVhE6UAChAwUQOlAAoQMFEDpQAKEDBYwN3fZVtt+2vWD7oO3tKzEMQHuavGHmlKTHkuy3/UNJ+2z/PcmHHW8D0JKxZ/QkR5PsH/35uKQFSeu6HgagPUt6jG57g6SNkvZ2MQZANxq/1932WkmvSXokyTfn+PfbJG1rcRuAljQK3fZFGka+M8nuc90myayk2dHt09pCAMvW5Fl3S3pR0kKSZ7ufBKBtTR6jb5b0gKTbbc+P/vlNx7sAtGjsXfckeyR5BbYA6AjvjAMKIHSgAEIHCiB0oABCBwrgKrDAeZw8ebLvCa3gjA4UQOhAAYQOFEDoQAGEDhRA6EABhA4UQOhAAYQOFEDoQAGEDhRA6EABhA4UQOhAAYQOFEDoQAGEDhRA6EABhA4UQOhAAYQOFEDoQAFO2v9V5vx+dJzLTTfd1Nmx9+3b19mxu9JFe4PBQHNzc4t+KSpndKAAQgcKIHSgAEIHCiB0oABCBwogdKCAxqHbXmX7gO3XuxwEoH1LOaNvl7TQ1RAA3WkUuu31ku6UtKPbOQC60PSM/pykxyV91+EWAB0ZG7rtuyR9leS8bya2vc32nO251tYBaEWTM/pmSXfb/kzSq5Jut/3y2TdKMptkkGTQ8kYAyzQ29CRPJlmfZIOkeyW9leT+zpcBaA2vowMFzCzlxknekfROJ0sAdIYzOlAAoQMFEDpQAKEDBRA6UMCSnnUHlmPt2rV9T1iyp556qrNj24su1toZzuhAAYQOFEDoQAGEDhRA6EABhA4UQOhAAYQOFEDoQAGEDhRA6EABhA4UQOhAAYQOFEDoQAGEDhRA6EABhA4UQOhAAYQOFEDoQAFO0v5B7fYPikU2bdrUyXHffffdTo47jbr6GkvdfZ2TLLq8LGd0oABCBwogdKAAQgcKIHSgAEIHCiB0oIBGodu+3PYu2x/ZXrB9c9fDALSn6a9Nfl7SG0l+a/tiSas73ASgZWNDt32ZpNsk/U6SkpyQdKLbWQDa1OSu+zWSjkl6yfYB2ztsr+l4F4AWNQl9RtKNkl5IslHSt5KeOPtGtrfZnrM91/JGAMvUJPQjko4k2Tv6eJeG4Z8hyWySQZJBmwMBLN/Y0JN8Kemw7WtHn9oi6cNOVwFoVdNn3R+StHP0jPsnkh7sbhKAtjUKPcm8JO6SA1OKd8YBBRA6UAChAwUQOlAAoQMFEDpQAJd77thg0N2rknNzvNsYi3G5Z6AoQgcKIHSgAEIHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwogdKAAQgcKIHSgAK4CO8VuvfXWTo67Z8+eTo6LM3Xx/29+fl7Hjx/nKrBARYQOFEDoQAGEDhRA6EABhA4UQOhAAY1Ct/2o7YO2P7D9iu1Luh4GoD1jQ7e9TtLDkgZJrpe0StK9XQ8D0J6md91nJF1qe0bSaklfdDcJQNvGhp7kc0nPSDok6aikr5O82fUwAO1pctf9Ckn3SLpa0pWS1ti+/xy322Z7zvZc+zMBLEeTu+53SPo0ybEkJyXtlnTL2TdKMptkkGTQ9kgAy9Mk9EOSNtlebduStkha6HYWgDY1eYy+V9IuSfslvT/6O7Md7wLQopkmN0rytKSnO94CoCO8Mw4ogNCBAggdKIDQgQIIHSiA0IECGr28hsl06tSpvidgGVbystqc0YECCB0ogNCBAggdKIDQgQIIHSiA0IECCB0ogNCBAggdKIDQgQIIHSiA0IECCB0ogNCBAggdKIDQgQIIHSiA0IECCB0ogNCBApyk/YPaxyT9q+HNfyTp362P6M607ZXYvBImZe9Pkvz47E92EvpS2J5LMuh1xBJM216JzSth0vdy1x0ogNCBAiYh9Nm+ByzRtO2V2LwSJnpv74/RAXRvEs7oADpG6EABhA4UQOhAAYQOFPBfzoY7o9WJabYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(norm_conf_mat, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('mnist_val_99_52.h5') # model with highest val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test / 255.0 #Normalize\n",
    "test = test.values.reshape(-1,28,28,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(y_test_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and write to file\n",
    "\n",
    "submit = pd.DataFrame({'ImageId': range(1,28001),                              \n",
    "                       'Label': y_test_pred})\n",
    "\n",
    "submit.to_csv('mnist1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
